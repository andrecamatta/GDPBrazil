{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Séries Temporais para Previsão\n",
    "\n",
    "Este notebook apresenta uma análise detalhada de um sistema de previsão de séries temporais, implementando técnicas avançadas de machine learning e validação cruzada específica para dados temporais.\n",
    "\n",
    "## Setup Inicial\n",
    "\n",
    "Primeiro, vamos configurar o ambiente e importar as bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configuração para exibir gráficos no notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# Importações básicas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Any, Tuple, List, Dict, Callable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from scipy.stats import kruskal, linregress\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.boxcox import LogTransformer\n",
    "from sktime.transformations.compose import TransformerPipeline\n",
    "from sktime.transformations.base import BaseTransformer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementação das Classes e Funções Base\n",
    "\n",
    "### 1.1 Transformadores Base\n",
    "\n",
    "Primeiro, implementamos os transformadores base que serão usados para processar nossas séries temporais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class PassThroughTransformer(BaseTransformer):\n",
    "    \"\"\"Transformer que não realiza nenhuma transformação, apenas retorna os dados como estão.\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X\n",
    "        \n",
    "    def inverse_transform(self, X):\n",
    "        return X\n",
    "\n",
    "class TotalGrowthTransformer(BaseTransformer):\n",
    "    \"\"\"Transformer que calcula o crescimento total entre t-h e t.\n",
    "    Para cada ponto t, calcula (X_t/X_{t-h} - 1).\"\"\"\n",
    "    def __init__(self, horizon=3):\n",
    "        super().__init__()\n",
    "        self.horizon = horizon\n",
    "        self._X = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.Series):\n",
    "            X = X.to_frame()\n",
    "        self._X = X.copy()\n",
    "        self._is_fitted = True\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        self.check_is_fitted()\n",
    "        single_series = isinstance(X, pd.Series)\n",
    "        if single_series:\n",
    "            X = X.to_frame()\n",
    "            \n",
    "        self._X = X.copy()\n",
    "        X_growth = pd.DataFrame()\n",
    "        \n",
    "        for col in X.columns:\n",
    "            current_values = X[col]\n",
    "            past_values = X[col].shift(self.horizon)\n",
    "            total_growth = (current_values / past_values) - 1\n",
    "            X_growth[col] = total_growth\n",
    "            \n",
    "        if single_series:\n",
    "            return X_growth.iloc[:, 0]\n",
    "        return X_growth\n",
    "        \n",
    "    def inverse_transform(self, X):\n",
    "        self.check_is_fitted()\n",
    "        single_series = isinstance(X, pd.Series)\n",
    "        if single_series:\n",
    "            X = X.to_frame()\n",
    "            \n",
    "        X_original = pd.DataFrame(index=X.index, columns=X.columns)\n",
    "        \n",
    "        for col in X.columns:\n",
    "            base_values = self._X[col].shift(self.horizon)\n",
    "            X_original[col] = base_values * (1 + X[col])\n",
    "            \n",
    "        if single_series:\n",
    "            return X_original.iloc[:, 0]\n",
    "        return X_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Funções de Transformação\n",
    "\n",
    "Implementamos várias funções auxiliares para criar diferentes tipos de transformadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def delta_seasonal_transformer(seasonality=12):\n",
    "    return Differencer(lags=seasonality)\n",
    "    \n",
    "def delta_seasonal_delta_transformer(seasonality=12):\n",
    "    return Differencer(lags=[1,seasonality])\n",
    "    \n",
    "def ln_transformer():\n",
    "    return LogTransformer()\n",
    "    \n",
    "def delta_ln_transformer():\n",
    "    return TransformerPipeline(steps=[\n",
    "        (\"log\", LogTransformer()),\n",
    "        (\"diff\", Differencer(lags=1))\n",
    "    ])\n",
    "\n",
    "def total_growth_ln_transformer(horizon=3):\n",
    "    return TotalGrowthTransformer(horizon=horizon)\n",
    "\n",
    "def delta_delta_ln_transformer():\n",
    "    return TransformerPipeline(steps=[\n",
    "        (\"log\", LogTransformer()),\n",
    "        (\"diff\", Differencer(lags=1)),\n",
    "        (\"diff2\", Differencer(lags=1))\n",
    "    ])\n",
    "\n",
    "def delta_transformer():\n",
    "    return Differencer(lags=1)\n",
    "\n",
    "def delta_delta_transformer():\n",
    "    return Differencer(lags=[1,1])\n",
    "\n",
    "def passthrough_transformer():\n",
    "    return PassThroughTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Funções de Verificação\n",
    "\n",
    "Implementamos funções para verificar características importantes das séries temporais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def check_stationarity(series):\n",
    "    \"\"\"Verifica estacionariedade usando o teste ADF.\"\"\"\n",
    "    adf_pvalue = adfuller(series.dropna(), autolag='AIC')[1]\n",
    "    return adf_pvalue < 0.05 \n",
    "\n",
    "def check_seasonality(series):\n",
    "    \"\"\"Verifica a presença de sazonalidade anual.\"\"\"\n",
    "    ts = series.dropna()\n",
    "    ts.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    stl = STL(ts, period=12, robust=True)\n",
    "    result = stl.fit()\n",
    "    seasonal = result.seasonal\n",
    "    \n",
    "    groups = [seasonal[i::12] for i in range(12)]\n",
    "    stat, p_value = kruskal(*groups)\n",
    "    kruskal_result = p_value < 0.05\n",
    "    \n",
    "    total_var = np.var(series)\n",
    "    seasonal_var = np.var(seasonal)\n",
    "    seasonal_strength = seasonal_var / total_var\n",
    "    seasonal_strength_result = seasonal_strength > 0.25\n",
    "    \n",
    "    return kruskal_result and seasonal_strength_result\n",
    "\n",
    "def check_proportional_variance(series):\n",
    "    \"\"\"Verifica se a variância é proporcional à magnitude.\"\"\"\n",
    "    ts = series.dropna()\n",
    "    abs_diff = abs(ts.diff()).dropna()\n",
    "    slope, _, r_value, p_value, _ = linregress(ts[1:], abs_diff)\n",
    "    return p_value < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Seleção de Transformador\n",
    "\n",
    "Implementamos a lógica para selecionar automaticamente o melhor transformador para cada série:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def transform_and_check(series, transformer):\n",
    "    transformed_series = transformer.fit_transform(series)\n",
    "    return check_stationarity(transformed_series)\n",
    "\n",
    "def select_transformer(series, seasonality=12):\n",
    "    \"\"\"Seleciona o transformador mais apropriado para a série.\"\"\"\n",
    "    seasonal_transformers = {\n",
    "        'ΔSazonal': delta_seasonal_transformer(seasonality),\n",
    "        'ΔSazonalΔ': delta_seasonal_delta_transformer(seasonality),\n",
    "    }\n",
    "\n",
    "    log_transformers = {\n",
    "        'ln(x)': ln_transformer(),\n",
    "        'Δln(x)': delta_ln_transformer(),\n",
    "        'ΔΔln(x)': delta_delta_ln_transformer(),\n",
    "    }\n",
    "\n",
    "    general_transformers = {\n",
    "        'Δx': delta_transformer(),\n",
    "        'ΔΔx': delta_delta_transformer(),\n",
    "    }\n",
    "\n",
    "    if check_stationarity(series):\n",
    "        return passthrough_transformer()\n",
    "\n",
    "    if check_seasonality(series):\n",
    "        for transformer in seasonal_transformers.values():\n",
    "            if transform_and_check(series, transformer):\n",
    "                return transformer\n",
    "    elif check_proportional_variance(series):\n",
    "        for transformer in log_transformers.values():\n",
    "            if transform_and_check(series, transformer):\n",
    "                return transformer\n",
    "    else:\n",
    "        for transformer in general_transformers.values():\n",
    "            if transform_and_check(series, transformer):\n",
    "                return transformer\n",
    "    \n",
    "    return passthrough_transformer()\n",
    "\n",
    "class StationarityTransformer(BaseTransformer):\n",
    "    \"\"\"Transformer que automaticamente seleciona e aplica a transformação mais apropriada para cada coluna.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.columns_transformers_ = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        for col in X.columns:\n",
    "            transformer = select_transformer(X[col])\n",
    "            transformer.fit(X[[col]])\n",
    "            self.columns_transformers_[col] = transformer\n",
    "        self._is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        self.check_is_fitted()\n",
    "        transformed_columns = []\n",
    "        for col in X.columns:\n",
    "            transformer = self.columns_transformers_[col]\n",
    "            transformed_col = transformer.transform(X[[col]])\n",
    "            transformed_columns.append(pd.DataFrame(transformed_col, index=X.index, columns=[col]))\n",
    "        return pd.concat(transformed_columns, axis=1)\n",
    "        \n",
    "    def inverse_transform(self, X):\n",
    "        self.check_is_fitted()\n",
    "        inverse_transformed_columns = []\n",
    "        for col in X.columns:\n",
    "            transformer = self.columns_transformers_[col]\n",
    "            inverse_transformed_col = transformer.inverse_transform(X[[col]])\n",
    "            inverse_transformed_columns.append(pd.DataFrame(inverse_transformed_col, index=X.index, columns=[col]))\n",
    "        return pd.concat(inverse_transformed_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Funções de Processamento de Dados\n",
    "\n",
    "Implementamos as funções principais para processamento dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class TargetTransformer:\n",
    "    \"\"\"Classe que encapsula a transformação do target e seus dados.\"\"\"\n",
    "    def __init__(self, y, horizon=3):\n",
    "        self.original_data = y\n",
    "        self.transformer = total_growth_ln_transformer(horizon=horizon)\n",
    "        self.transformed_data = None\n",
    "        self._fit_transform()\n",
    "    \n",
    "    def _fit_transform(self):\n",
    "        y_df = pd.DataFrame(self.original_data)\n",
    "        y_df.columns = ['target']\n",
    "        self.transformed_data = self.transformer.fit_transform(y_df)['target']\n",
    "    \n",
    "    def align_with_index(self, index):\n",
    "        self.original_data = self.original_data[index]\n",
    "        self.transformed_data = self.transformed_data[index]\n",
    "        \n",
    "    def get_data(self):\n",
    "        return self.original_data, self.transformed_data\n",
    "\n",
    "def create_lagged_features(X, lags=range(12)):\n",
    "    \"\"\"Cria features defasadas para cada coluna do DataFrame.\"\"\"\n",
    "    all_series = {}\n",
    "    \n",
    "    for column in X.columns:\n",
    "        all_series[f\"{column}_lag0\"] = X[column]\n",
    "        \n",
    "        for lag in lags:\n",
    "            if lag > 0:\n",
    "                all_series[f\"{column}_lag{lag}\"] = X[column].shift(lag)\n",
    "    \n",
    "    return pd.DataFrame(all_series, index=X.index)\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"Carrega e pré-processa o dataset inicial.\"\"\"\n",
    "    data = pd.read_csv('all_data.csv', parse_dates=True)\n",
    "    data.set_index(data.columns[0], inplace=True)\n",
    "    data = data.dropna()\n",
    "    data.index = pd.DatetimeIndex(data.index.values, freq='MS')\n",
    "    \n",
    "    y = data['target'].copy()\n",
    "    X = data.copy()\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def transform_features(X, y, horizon=3):\n",
    "    \"\"\"Transforma features para torná-las estacionárias e escaladas.\"\"\"\n",
    "    stationarity_transformer = StationarityTransformer()\n",
    "    X_stationary = stationarity_transformer.fit_transform(X)\n",
    "    \n",
    "    target_transformer = TargetTransformer(y, horizon=horizon)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_stationary_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_stationary),\n",
    "        index=X_stationary.index,\n",
    "        columns=X_stationary.columns\n",
    "    )\n",
    "    \n",
    "    X_with_lags = create_lagged_features(X_stationary_scaled)\n",
    "    X_with_lags = X_with_lags.dropna()\n",
    "    \n",
    "    target_transformer.align_with_index(X_with_lags.index)\n",
    "    \n",
    "    return X_with_lags, target_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Funções de Modelagem\n",
    "\n",
    "Implementamos as funções para treinar e fazer previsões com os modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_model_with_lagged_features(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    train_indices: List[int],\n",
    "    fh: int,\n",
    "    estimator: Any\n",
    ") -> Tuple[Any, MinMaxScaler, MinMaxScaler]:\n",
    "    \"\"\"Treina um modelo usando features defasadas.\"\"\"\n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    \n",
    "    for idx in train_indices:\n",
    "        if idx >= fh:\n",
    "            X_train_list.append(X.iloc[idx-fh].values)\n",
    "            y_train_list.append(y.iloc[idx])\n",
    "    \n",
    "    X_train = np.vstack(X_train_list)\n",
    "    y_train = np.array(y_train_list).reshape(-1, 1)\n",
    "    \n",
    "    X_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "    \n",
    "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train).ravel()\n",
    "    \n",
    "    model = estimator\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "    \n",
    "    return model, X_scaler, y_scaler\n",
    "\n",
    "def predict_next_steps(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    validation_indices: List[int],\n",
    "    model: Any,\n",
    "    X_scaler: MinMaxScaler,\n",
    "    y_scaler: MinMaxScaler,\n",
    "    fh: int = 3,\n",
    "    metric: Callable = mean_squared_error\n",
    ") -> Tuple[Dict[int, float], float]:\n",
    "    \"\"\"Faz previsões do crescimento total para os próximos fh passos.\"\"\"\n",
    "    predictions = {}\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    squared_errors = []\n",
    "    \n",
    "    for idx in validation_indices:\n",
    "        if idx >= fh:\n",
    "            current_features = X.iloc[idx-fh].values.reshape(1, -1)\n",
    "            current_features_scaled = X_scaler.transform(current_features)\n",
    "            pred_scaled = model.predict(current_features_scaled)[0]\n",
    "            pred = y_scaler.inverse_transform([[pred_scaled]])[0][0]\n",
    "            \n",
    "            predictions[idx] = pred\n",
    "            \n",
    "            if not np.isnan(y.iloc[idx]):\n",
    "                true_value = y.iloc[idx]\n",
    "                y_true.append(true_value)\n",
    "                y_pred.append(pred)\n",
    "                squared_errors.append((true_value - pred) ** 2)\n",
    "    \n",
    "    mse = np.mean(squared_errors) if len(y_true) > 0 else float('inf')\n",
    "    \n",
    "    return predictions, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validação Cruzada\n",
    "\n",
    "Implementamos um sistema robusto de validação cruzada específico para séries temporais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calculate_error_statistics(errors: List[float]) -> Dict[str, float]:\n",
    "    \"\"\"Calcula estatísticas detalhadas dos erros.\"\"\"\n",
    "    errors = np.array(errors)\n",
    "    return {\n",
    "        'min': np.min(errors),\n",
    "        'max': np.max(errors),\n",
    "        'mean': np.mean(errors),\n",
    "        'median': np.median(errors),\n",
    "        'std': np.std(errors),\n",
    "        'q1': np.percentile(errors, 25),\n",
    "        'q3': np.percentile(errors, 75),\n",
    "        'p90': np.percentile(errors, 90)\n",
    "    }\n",
    "\n",
    "class CustomSlidingWindowSplitter:\n",
    "    \"\"\"Divisor de janela deslizante personalizado para validação cruzada temporal.\"\"\"\n",
    "    def __init__(self, training_window: int, validation_window: int, fh: List[int], \n",
    "                 lag: int, differencer_lag: int, step: int):\n",
    "        self.training_window = training_window\n",
    "        self.validation_window = validation_window\n",
    "        self.fh = fh\n",
    "        self.lag = lag\n",
    "        self.differencer_lag = differencer_lag\n",
    "        self.step = step\n",
    "\n",
    "    def split(self, y):\n",
    "        \"\"\"Divide os dados em conjuntos de treinamento e validação.\"\"\"\n",
    "        n_samples = len(y)\n",
    "        start = max(self.lag, self.differencer_lag)\n",
    "        end = n_samples - self.validation_window - max(self.fh)\n",
    "\n",
    "        for train_start in range(start, end, self.step):\n",
    "            train_end = train_start + self.training_window\n",
    "            val_end = train_end + self.validation_window\n",
    "\n",
    "            if val_end > n_samples:\n",
    "                break\n",
    "\n",
    "            train_indices = list(range(train_start, train_end))\n",
    "            val_indices = list(range(train_end, val_end))\n",
    "\n",
    "            yield train_indices, val_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exemplo de Uso\n",
    "\n",
    "Aqui está um exemplo de como usar o sistema implementado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Carregar e preparar os dados\n",
    "X, y = load_and_preprocess_data()\n",
    "\n",
    "# Transformar as features\n",
    "X_with_lags, target_transformer = transform_features(X, y, horizon=3)\n",
    "\n",
    "# Configurar a validação cruzada\n",
    "cv = CustomSlidingWindowSplitter(\n",
    "    training_window=120,  # 10 anos de dados mensais\n",
    "    validation_window=24,  # 2 anos de dados mensais\n",
    "    fh=[3],  # Previsão 3 meses à frente\n",
    "    lag=12,  # 1 ano de defasagem\n",
    "    differencer_lag=12,\n",
    "    step=5\n",
    ")\n",
    "\n",
    "# Definir modelos para teste\n",
    "models = [\n",
    "    ('Ridge', Ridge(alpha=1.0)),\n",
    "    ('Lasso', Lasso(alpha=0.1)),\n",
    "    ('ElasticNet', ElasticNet(alpha=0.1, l1_ratio=0.5)),\n",
    "    ('RandomForest', RandomForestRegressor(n_estimators=100, max_depth=5)),\n",
    "    ('GradientBoosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1))\n",
    "]\n",
    "\n",
    "# Avaliar cada modelo\n",
    "for name, model in models:\n",
    "    print(f\"\\nAvaliando {name}...\")\n",
    "    fold_errors, test_stats, fold_y_preds = run_cross_validation(\n",
    "        X_with_lags=X_with_lags,\n",
    "        target_transformer=target_transformer,\n",
    "        cv=cv,\n",
    "        estimator=model,\n",
    "        target_column='target',\n",
    "        fh=3\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
